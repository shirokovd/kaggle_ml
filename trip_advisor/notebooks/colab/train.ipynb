{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4d3DTR5-fS41"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from enum import Enum\n",
    "\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EHyZzN3ejqUo",
    "outputId": "0a2f6641-407a-4742-adb4-a0a876b82349"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Last3roco5jM",
    "outputId": "53779a4b-d55d-4d93-dcf7-3f9b830cadae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BzKsIrMhttD"
   },
   "outputs": [],
   "source": [
    "TRAIN_CONST = 'train'\n",
    "VAL_CONST = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj-AYHm-hhxI"
   },
   "outputs": [],
   "source": [
    "def load_config(config_file):\n",
    "    with open(os.path.abspath(config_file)) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "def one_hot(a):\n",
    "    b = np.zeros((a.shape[0], a.max() + 1))\n",
    "    b[np.arange(a.shape[0]), a] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZ1ZUKPhiA0W"
   },
   "outputs": [],
   "source": [
    "class TokenizerType(Enum):\n",
    "    bert_tokenizer = 'bert_tokenizer'\n",
    "\n",
    "\n",
    "TOKENIZERS_CLASSES = {\n",
    "    TokenizerType.bert_tokenizer: BertTokenizer\n",
    "}\n",
    "\n",
    "\n",
    "class ModelType(Enum):\n",
    "    bert_for_sequence_classification = 'bert_for_sequence_classification'\n",
    "\n",
    "\n",
    "MODELS_CLASSES = {\n",
    "    ModelType.bert_for_sequence_classification: BertForSequenceClassification\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShYfPan9iQ5k"
   },
   "outputs": [],
   "source": [
    "class OptimizerType(Enum):\n",
    "    adam_w = 'adam_w'\n",
    "\n",
    "\n",
    "OPTIMIZERS_CLASSES = {\n",
    "    OptimizerType.adam_w: AdamW\n",
    "}\n",
    "\n",
    "\n",
    "class SchedulerType(Enum):\n",
    "    linear_schedule_with_warmup = 'linear_schedule_with_warmup'\n",
    "\n",
    "\n",
    "SCHEDULERS_CLASSES = {\n",
    "    SchedulerType.linear_schedule_with_warmup: get_linear_schedule_with_warmup\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XKsoVDWhS-4"
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, config_file):\n",
    "        self.input_label = 'input'\n",
    "        self.target_label = 'target'\n",
    "        self.prediction_label = 'predictions'\n",
    "\n",
    "        config = load_config(config_file)\n",
    "        self.device = config['model']['device']\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and self.device == 'gpu' else 'cpu')\n",
    "        print('Device = {}'.format(self.device))\n",
    "        if self.device == torch.device('cuda'):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        self._setup_output_config(config)\n",
    "        self._setup_data_config(config)\n",
    "        self._setup_model_config(config)\n",
    "\n",
    "    def _setup_data_config(self, config):\n",
    "        pass\n",
    "\n",
    "    def _setup_model_config(self, config):\n",
    "        pass\n",
    "\n",
    "    def _setup_output_config(self, config):\n",
    "        pass\n",
    "\n",
    "    def _save_prediction(self, input, targets, predictions, output_path):\n",
    "        prediction_df = pd.DataFrame(\n",
    "            data=\n",
    "            {\n",
    "                self.input_label: input,\n",
    "                self.target_label: targets,\n",
    "                self.prediction_label: predictions\n",
    "            }\n",
    "        )\n",
    "        prediction_df.to_csv(output_path, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "talkSFe_hZNj"
   },
   "outputs": [],
   "source": [
    "class Trainer(Evaluator):\n",
    "    def __init__(self, config_file):\n",
    "        super(Trainer, self).__init__(config_file)\n",
    "\n",
    "    def _setup_data_config(self, config):\n",
    "        self.train_df = pd.read_csv(config['dataset']['train_path'], sep=',')\n",
    "        self.val_df = pd.read_csv(config['dataset']['val_path'], sep=',')\n",
    "        self.input_label = config['dataset'].get('input_label', self.train_df.columns[0])\n",
    "        self.target_label = config['dataset'].get('target_label', self.train_df.columns[-1])\n",
    "        self.prediction_label = config['dataset'].get('target_label', 'prediction')\n",
    "\n",
    "        self.tokenizer = TOKENIZERS_CLASSES[TokenizerType[config['tokenizer']['type']]].from_pretrained(\n",
    "            config['tokenizer']['name'], do_lower_case=config['tokenizer']['do_lower_case']\n",
    "        )\n",
    "        encoded_train_data = self.tokenizer.batch_encode_plus(\n",
    "            self.train_df[self.input_label].values,\n",
    "            add_special_tokens=config['tokenizer']['add_special_tokens'],\n",
    "            return_attention_mask=config['tokenizer']['return_attention_mask'],\n",
    "            pad_to_max_length=config['tokenizer']['pad_to_max_length'],\n",
    "            max_length=config['tokenizer']['seq_length'],\n",
    "            return_tensors=config['tokenizer']['return_tensors']\n",
    "        )\n",
    "        train_input_ids = encoded_train_data['input_ids']\n",
    "        train_attention_masks = encoded_train_data['attention_mask']\n",
    "        train_labels = torch.tensor(one_hot(self.train_df[self.target_label].values))\n",
    "        train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "        self.train_loader = DataLoader(train_dataset,\n",
    "                                       sampler=RandomSampler(train_dataset),\n",
    "                                       batch_size=config['dataset']['batch_size'])\n",
    "\n",
    "        encoded_val_data = self.tokenizer.batch_encode_plus(\n",
    "            self.val_df[self.input_label].values,\n",
    "            add_special_tokens=config['tokenizer']['add_special_tokens'],\n",
    "            return_attention_mask=config['tokenizer']['return_attention_mask'],\n",
    "            pad_to_max_length=config['tokenizer']['pad_to_max_length'],\n",
    "            max_length=config['tokenizer']['seq_length'],\n",
    "            return_tensors=config['tokenizer']['return_tensors']\n",
    "        )\n",
    "        val_input_ids = encoded_val_data['input_ids']\n",
    "        val_attention_masks = encoded_val_data['attention_mask']\n",
    "        val_labels = torch.tensor(one_hot(self.val_df[self.target_label].values))\n",
    "        val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "        self.val_loader = DataLoader(val_dataset,\n",
    "                                     sampler=SequentialSampler(val_dataset),\n",
    "                                     batch_size=config['dataset']['batch_size'])\n",
    "\n",
    "    def _setup_model_config(self, config):\n",
    "        self.model = MODELS_CLASSES[ModelType[config['model']['type']]].from_pretrained(\n",
    "            config['model']['name'],\n",
    "            num_labels=config['model'].get(\n",
    "                'num_label',\n",
    "                len(np.unique(\n",
    "                    np.concatenate(\n",
    "                        (self.train_df[self.target_label].values, self.val_df[self.target_label].values),\n",
    "                        axis=0\n",
    "                    )\n",
    "                )\n",
    "                )\n",
    "            ),\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "        torch.save(self.model.state_dict(), os.path.join(self.model_path, 'init.pt'))\n",
    "        self.model.to(self.device)\n",
    "        self.epoch_count = config['eval']['epoch_count']\n",
    "        self.optimizer = OPTIMIZERS_CLASSES[OptimizerType[config['eval']['optimizer']]](\n",
    "            self.model.parameters(),\n",
    "            lr=config['eval']['lr'],\n",
    "            eps=config['eval']['eps']\n",
    "        )\n",
    "        self.scheduler = SCHEDULERS_CLASSES[SchedulerType[config['eval']['scheduler']]](\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=len(self.train_loader) * self.epoch_count\n",
    "        )\n",
    "\n",
    "    def _setup_output_config(self, config):\n",
    "        self.model_path = config['res']['model_path']\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "        self.tb_path = config['res']['tb_path']\n",
    "        os.makedirs(self.tb_path, exist_ok=True)\n",
    "        self.writer = SummaryWriter(log_dir=self.tb_path)\n",
    "        self.prediction_path = config['res']['prediction_path']\n",
    "        os.makedirs(self.prediction_path, exist_ok=True)\n",
    "        self.all_train_outputs = []\n",
    "        self.all_val_outputs = []\n",
    "        self.mean_epoch_loss = None\n",
    "\n",
    "    def epoch(self, epoch_num, mode):\n",
    "        batch_num = 0\n",
    "        epoch_losses = list()\n",
    "        loader = None\n",
    "        all_outputs = list()\n",
    "        target = list()\n",
    "        if mode == TRAIN_CONST:\n",
    "            self.model.train(True)\n",
    "            loader = self.train_loader\n",
    "            target = self.train_df[self.target_label].values\n",
    "        elif mode == VAL_CONST:\n",
    "            self.model.eval()\n",
    "            loader = self.val_loader\n",
    "            target = self.val_df[self.target_label].values\n",
    "        epoch_start = time.perf_counter()\n",
    "        for batch in tqdm(loader, desc='Epoch {}, {}'.format(epoch_num + 1, mode)):\n",
    "            self.model.zero_grad()\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(self.device)\n",
    "            attention_mask = attention_mask.to(torch.uint8).to(self.device)\n",
    "            labels = labels.to(torch.float32).to(self.device)\n",
    "            if mode == TRAIN_CONST:\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            epoch_loss = outputs.loss\n",
    "            epoch_losses.append(epoch_loss.item())\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_outputs.append(preds.detach().cpu().numpy())\n",
    "            epoch_loss.backward() if mode == TRAIN_CONST else 0\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0) if mode == TRAIN_CONST else 0\n",
    "            self.optimizer.step() if mode == TRAIN_CONST else 0\n",
    "            self.scheduler.step() if mode == TRAIN_CONST else 0\n",
    "            batch_num += 1\n",
    "        epoch_end = time.perf_counter()\n",
    "        all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "\n",
    "        self.mean_epoch_loss = np.mean(epoch_losses)\n",
    "        self.writer.add_scalar('Loss/{}'.format(mode), self.mean_epoch_loss, epoch_num)\n",
    "\n",
    "        accuracy = accuracy_score(target, all_outputs)\n",
    "        self.writer.add_scalar('Accuracy/{}'.format(mode), accuracy, epoch_num)\n",
    "\n",
    "        print('Mean loss = {0}, accuracy = {1:.3f},  time: {2:.7f}'.format(\n",
    "            self.mean_epoch_loss, accuracy,\n",
    "            epoch_end - epoch_start)\n",
    "        )\n",
    "        return all_outputs\n",
    "\n",
    "    def train(self):\n",
    "        for epoch_num in range(self.epoch_count):\n",
    "            self.all_train_outputs = self.epoch(epoch_num, mode=TRAIN_CONST)\n",
    "            torch.save(\n",
    "                self.model.state_dict(),\n",
    "                os.path.join(\n",
    "                    self.model_path,\n",
    "                    'epoch={0}_loss={1:.7f}.pt'.format(epoch_num, self.mean_epoch_loss)\n",
    "                )\n",
    "            )\n",
    "            self._save_prediction(\n",
    "                self.train_df[self.input_label].values,\n",
    "                self.train_df[self.target_label].values,\n",
    "                self.all_train_outputs,\n",
    "                os.path.join(self.prediction_path, 'train_epoch={}.csv'.format(epoch_num))\n",
    "            )\n",
    "            self.all_val_outputs = self.epoch(epoch_num, mode=VAL_CONST)\n",
    "            self._save_prediction(\n",
    "                self.val_df[self.input_label].values,\n",
    "                self.val_df[self.target_label].values,\n",
    "                self.all_val_outputs,\n",
    "                os.path.join(self.prediction_path, 'val_epoch={}.csv'.format(epoch_num))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5wSUhahrA3J",
    "outputId": "95a3657f-4397-4db7-90f5-5fbe7c9db200",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1, train: 100%|██████████| 926/926 [21:10<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.32844114071864544, accuracy = 0.339,  time: 1270.7917517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, val: 100%|██████████| 164/164 [01:23<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.2883703247984735, accuracy = 0.644,  time: 83.5038896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, train: 100%|██████████| 926/926 [21:20<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.2634850988088107, accuracy = 0.317,  time: 1280.7973652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, val: 100%|██████████| 164/164 [01:23<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.2841940712092853, accuracy = 0.650,  time: 83.6330375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, train: 100%|██████████| 926/926 [21:20<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.22448270273099194, accuracy = 0.304,  time: 1280.2892721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, val: 100%|██████████| 164/164 [01:23<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.30258184312502057, accuracy = 0.656,  time: 83.6512787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, train: 100%|██████████| 926/926 [21:19<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.18313788907445533, accuracy = 0.310,  time: 1279.7670448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, val: 100%|██████████| 164/164 [01:23<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.3169262011694472, accuracy = 0.655,  time: 83.7160004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, train: 100%|██████████| 926/926 [21:20<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.1479131047720528, accuracy = 0.314,  time: 1280.4052771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, val: 100%|██████████| 164/164 [01:23<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss = 0.3384379159386565, accuracy = 0.655,  time: 83.9707626\n"
     ]
    }
   ],
   "source": [
    "config_file = '/content/config(colab).yml'\n",
    "trainer = Trainer(config_file)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
